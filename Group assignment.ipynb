{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stappenplan en verdeling\n",
    "\n",
    "1. aanmaken github\n",
    "2. data preprocessing (verwijder duplicates and NaN)\n",
    "3. bepaal de relevante features van de descriptors via een PCA\n",
    "4. wat wordt test en wat wordt train\n",
    "5. aanmaken model voor het maken van voorspellingen\n",
    "    5.1 uitproberen welke methodes er toepasbaar zijn (random forest, k-NN)\n",
    "    5.2 bepalen welke methode het beste is\n",
    "6. verslag en presentatie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Richard\n",
    "2. Luuk, Richard\n",
    "3. Robin, Tijn, Rik & Yael\n",
    "4. \n",
    "5. Julien & Branco\n",
    "6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Onderzoek over random forest methode\n",
    "The random forest algorithm is an extension of the bagging method as it utilizes both bagging and feature randomness to create an uncorrelated forest of decision trees. While decision trees consider all the possible feature splits, random forests only select a subset of those features.\n",
    "\n",
    "Random forest algorithms have three main hyperparameters, which need to be set before training. These include node size, the number of trees, and the number of features sampled. From there, the random forest classifier can be used to solve for regression or classification problems.\n",
    "\n",
    "> Dit betekent dat alle descriptors onze features zijn waarvan per tree een random keuze wordt gemaakt. \n",
    "> The nodesize parameter specifies the minimum number of observations in a terminal node. Setting it lower leads to trees with a larger depth which means that more splits are performed until the terminal nodes.\n",
    "\n",
    "The random forest algorithm is made up of a collection of decision trees, and each tree in the ensemble is comprised of a data sample drawn from a training set with replacement, called the bootstrap sample. Of that training sample, one-third of it is set aside as test data, known as the out-of-bag (oob) sample, which we’ll come back to later. Another instance of randomness is then injected through feature bagging, adding more diversity to the dataset and reducing the correlation among decision trees. Depending on the type of problem, the determination of the prediction will vary.\n",
    "\n",
    "> Dit geeft dus aan dat onze verschillende moleculen niet allemaal tegelijk moeten worden gebruikt maar in secties. De grote van deze sectie is denk ik voor onszelf te bepalen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful functions:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "#Hiermee importeren we de RandomForestClassifier functie.\n",
    "\n",
    "# Load the dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "#RandomForestClassifier() kan veel parameters gebruiken. De belangrijkste hiervan is n_estimators. Deze parameter bepaalt de hoeveelheid decision trees. Sommige parameters, zoals max_leaf_nodes, welke de maximale hoeveelheid verschillende ‘kruispunten’ in elke decision tree bepaalt, kunnen worden gebruikt om het model te optimaliseren.\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "#Deze functie fit het model op onze data. Xtrain en Ytrain zijn in dit geval training data. Dat is dus die file tested_molecules.csv. \n",
    "\n",
    "Ypredicted = rf.predict(X_test)\n",
    "#Nadat het model is gefit, kunnen met deze functie de waardes voor onze test data berekend worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
