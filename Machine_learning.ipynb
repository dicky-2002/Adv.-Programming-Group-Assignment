{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from pandas.plotting import scatter_matrix \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tested data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the .csv file\n",
    "data = pd.read_csv('cleaned_descriptor_data',index_col=0)\n",
    "X_fingerprints=pd.read_csv('fingerprint_data',index_col=0)\n",
    "\n",
    "# Scale the data with a standard scaling\n",
    "scaling=MinMaxScaler()\n",
    "scaling.fit(data)\n",
    "scaled_data=scaling.transform(data)\n",
    "df_data = pd.DataFrame(scaled_data, columns=data.columns,index=data.index)\n",
    "\n",
    "# Choose the kinase of which you want to predict the inhibition\n",
    "kinase_ERK2 = 'ERK2_inhibition'\n",
    "kinase_PKM2 = 'PKM2_inhibition'    \n",
    "\n",
    "# Define train and test data\n",
    "X = df_data.drop(columns=['ERK2_inhibition','PKM2_inhibition']).copy()\n",
    "y_pkm2 = data[kinase_PKM2].copy()\n",
    "y_erk2 = data[kinase_ERK2].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load untested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_molecules=pd.read_csv('cleaned_descriptor_data_untested',index_col=0)\n",
    "untested_molecules.head()\n",
    "X_untested=untested_molecules.drop(columns=['ERK2_inhibition','PKM2_inhibition']).copy()\n",
    "\n",
    "y_untested_erk2=untested_molecules[kinase_ERK2].copy()\n",
    "y_untested_pkm2=untested_molecules[kinase_PKM2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_untested_fingerprints=pd.read_csv('fingerprint_data_untested',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MaxAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'HeavyAtomMolWt',\n",
      "       'MinPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2',\n",
      "       'FpDensityMorgan3', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO',\n",
      "       'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW',\n",
      "       'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi1v', 'Chi3v', 'Ipc', 'PEOE_VSA1',\n",
      "       'PEOE_VSA11', 'PEOE_VSA5', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9',\n",
      "       'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA3', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA9',\n",
      "       'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA5', 'SlogP_VSA6',\n",
      "       'EState_VSA3', 'EState_VSA6', 'VSA_EState1', 'VSA_EState2',\n",
      "       'VSA_EState5', 'VSA_EState6', 'VSA_EState9', 'NumAromaticHeterocycles',\n",
      "       'MolLogP', 'fr_Ar_N', 'fr_sulfonamd'],\n",
      "      dtype='object')\n",
      "Index(['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed',\n",
      "       'SPS', 'MinPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1',\n",
      "       'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_LOGPHI',\n",
      "       'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ',\n",
      "       'Chi0n', 'Chi3v', 'HallKierAlpha', 'Kappa1', 'PEOE_VSA1', 'PEOE_VSA6',\n",
      "       'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10',\n",
      "       'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA2',\n",
      "       'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA8', 'TPSA', 'EState_VSA3',\n",
      "       'EState_VSA4', 'EState_VSA5', 'VSA_EState1', 'VSA_EState2',\n",
      "       'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState7',\n",
      "       'VSA_EState8', 'VSA_EState9', 'MolLogP', 'fr_ether'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfe_pmk = RFE(RandomForestClassifier(), n_features_to_select=50)\n",
    "rfe_pmk.fit(X, y_pkm2)\n",
    "selected_features_pmk = X.columns[rfe_pmk.support_]\n",
    "print(selected_features_pmk)\n",
    "\n",
    "rfe_erk = RFE(RandomForestClassifier(), n_features_to_select=50)\n",
    "rfe_erk.fit(X, y_erk2)\n",
    "selected_features_erk = X.columns[rfe_erk.support_]\n",
    "print(selected_features_erk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned_pmk=X[selected_features_pmk]\n",
    "X_untested_cleaned_pmk=X_untested[selected_features_pmk]\n",
    "\n",
    "X_cleaned_erk=X[selected_features_erk]\n",
    "X_untested_cleaned_erk=X_untested[selected_features_erk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with descriptors evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# ERK2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned_erk, y_erk2, test_size=0.2, stratify=y_erk2, random_state=40)\n",
    "\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=10)],['classifier', RandomForestClassifier()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=40)\n",
    "    \n",
    "param_grid = {'classifier__n_estimators':[100, 200, 300, 400, 500, 600]}\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='recall', cv=stratified_kfold, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "n_estimators_erk = grid_search.best_params_['classifier__n_estimators']\n",
    "print(n_estimators_erk)\n",
    "\n",
    "# PMK2\n",
    "X_train_pmk, X_test_pmk, y_train_pmk, y_test_pmk = train_test_split(X_cleaned_pmk, y_pkm2, test_size=0.2, stratify=y_pkm2, random_state=40)\n",
    "\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=10)],['classifier', RandomForestClassifier()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=40)\n",
    "    \n",
    "param_grid = {'classifier__n_estimators':[100, 200, 300, 400, 500, 600]}\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='recall', cv=stratified_kfold, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_pmk, y_train_pmk)\n",
    "n_estimators_pmk = grid_search.best_params_['classifier__n_estimators']\n",
    "print(n_estimators_pmk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of 0 and 1 inhibitors in the balanced training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: ERK2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.9375\n",
      "1    0.0625\n",
      "Name: ERK2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [0.99531616 0.98130841]\n",
      "Confusion Matrix:\n",
      "[[208   2]\n",
      " [ 13   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       210\n",
      "           1       0.33      0.07      0.12        14\n",
      "\n",
      "    accuracy                           0.93       224\n",
      "   macro avg       0.64      0.53      0.54       224\n",
      "weighted avg       0.90      0.93      0.91       224\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the balanced training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.977679\n",
      "1    0.022321\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [0.99539171 1.        ]\n",
      "Confusion Matrix:\n",
      "[[218   1]\n",
      " [  5   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       219\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.97       224\n",
      "   macro avg       0.49      0.50      0.49       224\n",
      "weighted avg       0.96      0.97      0.96       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ERK2:\n",
    "# Split the data into training and test sets\n",
    "X_train_erk, X_test_erk, y_train_erk, y_test_erk = train_test_split(X_cleaned_erk, y_erk2, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote_erk = SMOTE(random_state=40)\n",
    "X_train_balanced_erk, y_train_balanced_erk = smote_erk.fit_resample(X_train_erk, y_train_erk)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced_erk = y_train_balanced_erk.value_counts(normalize=True)\n",
    "ratio_test_erk = y_test_erk.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the balanced training set:\")\n",
    "print(ratio_train_balanced_erk)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test_erk)\n",
    "\n",
    "# Train the Random Forest model with the balanced training set\n",
    "rf_descriptors = RandomForestClassifier(n_estimators_erk)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores = cross_val_score(rf_descriptors, X_train_balanced_erk, y_train_balanced_erk, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "\n",
    "rf_descriptors.fit(X_train_balanced_erk, y_train_balanced_erk)\n",
    "y_pred_erk = rf_descriptors.predict(X_test_erk)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_mat_erk = confusion_matrix(y_test_erk, y_pred_erk)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat_erk)\n",
    "print(classification_report(y_test_erk, y_pred_erk))\n",
    "\n",
    "\n",
    "#PMK:\n",
    "# Split the data into training and test sets\n",
    "X_train_pmk, X_test_pmk, y_train_pmk, y_test_pmk = train_test_split(X_cleaned_pmk, y_pkm2, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote_pmk = SMOTE(random_state=40)\n",
    "X_train_balanced_pmk, y_train_balanced_pmk = smote_pmk.fit_resample(X_train_pmk, y_train_pmk)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced_pmk = y_train_balanced_pmk.value_counts(normalize=True)\n",
    "ratio_test_pmk = y_test_pmk.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the balanced training set:\")\n",
    "print(ratio_train_balanced_pmk)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test_pmk)\n",
    "\n",
    "# Train the Random Forest model with the balanced training set\n",
    "rf_descriptors_pmk = RandomForestClassifier(n_estimators_pmk, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores_pmk= cross_val_score(rf_descriptors, X_train_balanced_pmk, y_train_balanced_pmk, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores_pmk}')\n",
    "\n",
    "rf_descriptors_pmk.fit(X_train_balanced_pmk, y_train_balanced_pmk)\n",
    "y_pred_pmk = rf_descriptors_pmk.predict(X_test_pmk)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_mat_pmk = confusion_matrix(y_test_pmk, y_pred_pmk)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat_pmk)\n",
    "print(classification_report(y_test_pmk, y_pred_pmk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with fingerprints evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of 0 and 1 inhibitors in the balanced training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: ERK2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.955357\n",
      "1    0.044643\n",
      "Name: ERK2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [0.94823529 0.99765258]\n",
      "Confusion Matrix:\n",
      "[[208   6]\n",
      " [ 10   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       214\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.93       224\n",
      "   macro avg       0.48      0.49      0.48       224\n",
      "weighted avg       0.91      0.93      0.92       224\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the balanced training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.96875\n",
      "1    0.03125\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [0.9816092 1.       ]\n",
      "Confusion Matrix:\n",
      "[[216   1]\n",
      " [  7   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       217\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.96       224\n",
      "   macro avg       0.48      0.50      0.49       224\n",
      "weighted avg       0.94      0.96      0.95       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ERK2:\n",
    "# Split the data into training and test sets\n",
    "X_train_erk, X_test_erk, y_train_erk, y_test_erk = train_test_split(X_fingerprints, y_erk2, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote_erk = SMOTE(random_state=40)\n",
    "X_train_balanced_finger_erk, y_train_balanced_finger_erk = smote_erk.fit_resample(X_train_erk, y_train_erk)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced_erk = y_train_balanced_erk.value_counts(normalize=True)\n",
    "ratio_test_erk = y_test_erk.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the balanced training set:\")\n",
    "print(ratio_train_balanced_erk)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test_erk)\n",
    "\n",
    "# Train the Random Forest model with the balanced training set\n",
    "rf_finger_erk = RandomForestClassifier(n_estimators_erk, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores = cross_val_score(rf_descriptors, X_train_balanced_finger_erk, y_train_balanced_finger_erk, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "\n",
    "rf_finger_erk.fit(X_train_balanced_finger_erk, y_train_balanced_finger_erk)\n",
    "y_pred_erk = rf_finger_erk.predict(X_test_erk)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_mat_erk = confusion_matrix(y_test_erk, y_pred_erk)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat_erk)\n",
    "print(classification_report(y_test_erk, y_pred_erk))\n",
    "\n",
    "\n",
    "#PMK:\n",
    "# Split the data into training and test sets\n",
    "X_train_pmk, X_test_pmk, y_train_pmk, y_test_pmk = train_test_split(X_fingerprints, y_pkm2, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote_pmk = SMOTE(random_state=40)\n",
    "X_train_balanced_finger_pmk, y_train_balanced_finger_pmk = smote_pmk.fit_resample(X_train_pmk, y_train_pmk)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced_pmk = y_train_balanced_pmk.value_counts(normalize=True)\n",
    "ratio_test_pmk = y_test_pmk.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the balanced training set:\")\n",
    "print(ratio_train_balanced_pmk)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test_pmk)\n",
    "\n",
    "# Train the Random Forest model with the balanced training set\n",
    "rf_finger_pmk = RandomForestClassifier(n_estimators_pmk, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores_pmk= cross_val_score(rf_descriptors, X_train_balanced_finger_pmk, y_train_balanced_finger_pmk, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores_pmk}')\n",
    "\n",
    "rf_finger_pmk.fit(X_train_balanced_finger_pmk, y_train_balanced_finger_pmk)\n",
    "y_pred_pmk = rf_finger_pmk.predict(X_test_pmk)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_mat_pmk = confusion_matrix(y_test_pmk, y_pred_pmk)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat_pmk)\n",
    "print(classification_report(y_test_pmk, y_pred_pmk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with descriptors on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pmk = SMOTE(random_state=40)\n",
    "X_balanced_pmk, y_balanced_pmk = smote_pmk.fit_resample(X_cleaned_pmk, y_pkm2)\n",
    "\n",
    "rf_descriptors_pmk = RandomForestClassifier(n_estimators_pmk)\n",
    "rf_descriptors_pmk.fit(X_balanced_pmk, y_balanced_pmk)\n",
    "y_pred_descriptor_pmk = rf_descriptors_pmk.predict(X_untested_cleaned_pmk)\n",
    "df_y_pred_descriptor_pmk=pd.DataFrame(y_pred_descriptor_pmk,index=untested_molecules.index)\n",
    "\n",
    "smote_erk = SMOTE(random_state=40)\n",
    "X_balanced_erk, y_balanced_erk = smote_erk.fit_resample(X_cleaned_erk, y_erk2)\n",
    "\n",
    "rf_descriptors_erk = RandomForestClassifier(n_estimators_erk)\n",
    "rf_descriptors_erk.fit(X_balanced_erk, y_balanced_erk)\n",
    "y_pred_descriptor_erk = rf_descriptors.predict(X_untested_cleaned_erk)\n",
    "df_y_pred_descriptor_erk=pd.DataFrame(y_pred_descriptor_erk,index=untested_molecules.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with fingerprints on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_erk = SMOTE(random_state=40)\n",
    "X_fingerprints_pkm, y_fingerprints_pkm = smote_erk.fit_resample(X_fingerprints, y_pkm2)\n",
    "rf_fingerprints_pmk = RandomForestClassifier(n_estimators_pmk)\n",
    "rf_fingerprints_pmk.fit(X_fingerprints_pkm, y_balanced_pmk)\n",
    "y_pred_fingerprint_pmk = rf_fingerprints_pmk.predict(X_untested_fingerprints)\n",
    "df_y_pred_fingerprint_pmk=pd.DataFrame(y_pred_fingerprint_pmk,index=untested_molecules.index)\n",
    "\n",
    "smote_erk = SMOTE(random_state=40)\n",
    "X_fingerprints_erk, y_fingerprints_erk = smote_erk.fit_resample(X_fingerprints, y_erk2)\n",
    "rf_fingerprints_erk = RandomForestClassifier(n_estimators_erk)\n",
    "rf_fingerprints_erk.fit(X_fingerprints_erk, y_balanced_erk)\n",
    "y_pred_fingerprint_erk = rf_fingerprints_erk.predict(X_untested_fingerprints)\n",
    "df_y_pred_fingerprint_erk=pd.DataFrame(y_pred_fingerprint_erk,index=untested_molecules.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_pmk=untested_molecules[(df_y_pred_descriptor_pmk[0]==1)|(df_y_pred_fingerprint_pmk[0]==1)].index\n",
    "len(intersect_pmk)\n",
    "\n",
    "intersect_erk=untested_molecules[(df_y_pred_descriptor_erk[0]==1)|(df_y_pred_fingerprint_erk[0]==1)].index\n",
    "len(intersect_erk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing outcomes to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O=P([O-])(CP(=O)(c1ccccc1)c1ccccc1)c1ccccc1\n",
      "O=c1nc[nH]c2c1ncn2[C@H]1CC[C@@H](CO)O1\n",
      "C=CC[C@@](O)(CC[NH+]1CCCCC1)c1ccccc1\n",
      "Fc1ccc(Nc2nc(Oc3ccc4c(c3)OCO4)nc(N3CCOCC3)n2)c(F)c1\n",
      "c1cc(CNc2ccc3c(c2)OCO3)ccn1\n",
      "O=P(Nc1nccs1)(c1ccccc1)c1ccccc1\n",
      "C[NH+](C)CCOC(c1ccccc1)c1ccccc1\n",
      "O/N=C1/CCc2nonc2/C1=N/O\n",
      "O=c1c2ccccc2nc2n1CCS2\n",
      "COc1cc(C(=O)Nc2ccncc2)cc(OC)c1OC\n",
      "COc1ccn(C)c(=O)c1C#N\n",
      "c1nc(N2CCCC2)c2[nH]cnc2n1\n",
      "O=C1C(C2=C([O-])c3ccccc3C2=O)=Nc2ccccc21\n",
      "COc1ccc(CN2CC[NH2+]CC2)c(OC)c1OC\n",
      "C=CCNc1ncnc2ccc(Br)cc12\n",
      "COc1ccc(S(=O)(=O)c2ccc(OC)c(OC)c2)cc1OC\n",
      "OCc1ccccc1C[NH2+]Cc1ccccc1\n",
      "CN1C[N@H+](C)CSC1=S\n",
      "C(=N/c1c(-c2ccccc2)nc2n1CCS2)\\c1ccccc1\n",
      "O=C1C[C@H](c2ccccc2)Sc2ccccc2N1\n",
      "COc1cc(-c2ccccc2)nc(N)n1\n",
      "Nc1ccc(/N=N/c2ccccc2)c(N)n1\n",
      "C[C@@H]1C(=O)[C@@H](C)[C@@H](c2ccc3c(c2)OCO3)[NH2+][C@@H]1c1ccc2c(c1)OCO2\n",
      "N#CC1=C2C=CC=CN2CC1=O\n",
      "COc1ccc2ccccc2c1/C=N/O\n",
      "Oc1ccc(Nc2nc(N3CCCC3)c3ccccc3n2)cc1\n",
      "COCCNc1nc([S-])nc2cc(OC)c(OC)cc12\n",
      "O=P([O-])([O-])c1ccccc1OCCOCCOc1ccccc1P(=O)([O-])[O-]\n",
      "O=C1CC(c2ccccc2)CC(=O)C1=C[NH2+]Cc1ccco1\n",
      "COc1ccc(-c2cc(N)n(S(=O)(=O)c3c(F)c(F)c(F)c(F)c3F)n2)cc1OC\n",
      "c1ccc(CNc2ncnc3ccccc23)cc1\n",
      "C1COC(NC(C2CC2)C2CC2)=[NH+]1\n",
      "O=S(=O)(NCCNS(=O)(=O)c1ccccc1)c1ccccc1\n",
      "C[C@H]1O[C@@H]2[C@@H](O[C@@H]1C)N(S(C)(=O)=O)CCN2S(C)(=O)=O\n",
      "O[C@H](c1ccc2c(c1)OCO2)c1nccc2ccccc12\n",
      "O=P(c1ccccc1)(c1ccccc1)[C@@H](O)c1ccncc1\n",
      "[S-]c1nc(C2CC2)nc2ccccc12\n",
      "O=S(=O)(Cc1ccccc1)N1CC[NH+](C/C=C/c2ccccc2)CC1\n",
      "O=C1c2ccccc2C(=O)N1OCCOCCOCCON1C(=O)c2ccccc2C1=O\n",
      "O=C1c2ccccc2[C@H](Nc2ccc3c(c2)OCO3)N1Cc1ccco1\n",
      "COc1ccc(OC)c([C@H](O)[C@@H](C)[NH3+])c1\n",
      "C[N+]1=C2c3ccccc3N=CN2CC1\n",
      "O=P(OCC(F)(F)C(F)F)(N1CCOCC1)N1CCOCC1\n",
      "c1ccc(Nc2cc(Nc3ccccc3)[nH]n2)cc1\n",
      "c1ccc(OCCOc2ncnc3sccc23)cc1\n",
      "COc1cc2[nH]c3c(N4CCN(c5ccccn5)CC4)ncnc3c2cc1OC\n",
      "O=C1C=CC(=O)C2=C1C1c3ccccc3C2c2ccccc21\n",
      "O=c1cc(-c2ccccc2)nc2nc(CCc3ccccc3)[nH]n12\n",
      "O=C(NC1=[NH+]CCS1)c1ccc(Cl)s1\n",
      "O=C(Nc1nc(-c2ccccc2)ns1)c1cccs1\n",
      "c1cncc(Nc2nc(-c3ccncc3)cs2)c1\n",
      "O=S(=O)(c1ccc(N2CC=C(c3ccccc3)CC2)nc1)N1CCCC1\n",
      "OC1(c2cccc(C(F)(F)F)c2)CC[NH2+]CC1\n",
      "C(=N/n1cnnc1)\\c1ccccc1OCCOc1ccccc1\n",
      "C=CS(=O)(=O)c1ccc(Oc2ccc(S(=O)(=O)C=C)cc2)cc1\n",
      "c1ccc(C2=Nn3c(nnc3-c3ccncc3)SC2)cc1\n",
      "CC(C)[C@]12CN3C[C@](C(C)C)(C[NH+](C1)[C@H]3c1ccccc1)C2O\n",
      "O=S(=O)(c1cccc(S(=O)(=O)N2CCCC2)c1)c1cccc(S(=O)(=O)N2CCCC2)c1\n",
      "COc1cc(S(=O)(=O)N(C)C)ccc1F\n",
      "[O-][n+]1onc2c1CCc1nnccc1-2\n",
      "COc1ccc(OC)c(C2=[N+]([O-])C(C)(C)C(C)(C)[N+]([O-])=C2)c1\n",
      "O=C(/C=C/c1ccc(O)cc1)c1c(O)cc(O)cc1O\n",
      "CC(=O)Nc1nc(-c2ccc(Br)s2)cs1\n",
      "[O-]/[N+](=C/c1ccc(F)cc1)c1ccccc1\n",
      "c1cc(-c2sc(-c3ccncc3)c(-c3ccncc3)c2-c2ccncc2)ccn1\n",
      "CC(C)(C)C1=C[C@@H](CO)C[C@@H](CO)C1\n",
      "N=c1nc(-c2ccccc2)ccn1O\n",
      "Oc1ccccc1-c1cc(-c2ccc3c(c2)OCCO3)n[nH]1\n",
      "C[C@H](C(N)=O)N1C(=O)[C@@H]2[C@H](C1=O)[C@@H]1C=C[C@H]2C1\n",
      "CN(C)S(=O)(=O)N1CCN(S(=O)(=O)N(C)C)CC1\n",
      "O=C(Nc1ccc2c(c1)OCO2)c1c(F)c(F)c(F)c(F)c1F\n",
      "Fc1cc2nccnc2cc1N1CCSCC1\n",
      "CSc1nc2ccc(S(=O)(=O)N3CCc4ccccc43)cc2s1\n",
      "c1ccc2c(c1)nc1sccn12\n",
      "Cc1ccnc2nc(C(=O)N3CCN(S(=O)(=O)c4ccccc4)CC3)nn12\n",
      "O=C(c1ccccc1C(F)(F)F)N1CCN(S(=O)(=O)c2ccccc2)CC1\n",
      "O=C(OCCN1C(=O)CCC1=O)c1ccc(S(=O)(=O)N2CCCCC2)cc1\n",
      "CSC1=[NH+]CCN1C(=O)c1ccc(S(=O)(=O)N2CCCC2)cc1\n",
      "O=S(=O)(Nc1nccs1)c1ccc(NS(=O)(=O)c2cccs2)cc1\n",
      "Cn1cnc(S(=O)(=O)NCc2cccs2)c1\n",
      "O=S(=O)(Nc1cccnc1)c1cccs1\n",
      "COc1ccc(S(=O)(=O)N2CCN(S(=O)(=O)c3ccc4c(c3)OCCO4)CC2)cc1C\n",
      "O=S(=O)(c1ccc2c(c1)OCCO2)N1CC[NH+](Cc2ccc3c(c2)OCO3)CC1\n",
      "CSc1nn(CCc2ccncc2)c(=S)s1\n",
      "O=C(c1ccc(S(=O)(=O)N2CCCC2)cc1)N1CC[NH+](Cc2ccc3c(c2)OCO3)CC1\n",
      "O=c1c2ccccc2ncn1Cc1nc2ccccc2s1\n",
      "c1ccc2c(c1)ncn2CCn1cnc2ccccc21\n",
      "Cc1ccccc1CNS(=O)(=O)c1ccc2c(c1)OCCO2\n",
      "COc1ccc(S(=O)(=O)N2CCN(C(=O)c3cccs3)CC2)cc1\n",
      "O=S(=O)(c1ccc2c(c1)OCCO2)N1CCN(c2ccccc2)CC1\n",
      "C=CCn1c(-c2cccs2)nc2ccccc21\n",
      "Cc1ccc(CNc2nc3ccccc3s2)s1\n",
      "O=S(=O)(NCCNS(=O)(=O)c1ccccc1)c1ccccc1\n",
      "Cc1sc2ncnc(OCC(=O)N3CCN(S(=O)(=O)c4ccccc4)CC3)c2c1C\n",
      "COc1ccc(S(=O)(=O)N2CCN(S(=O)(=O)c3ccc4c(c3)OCCO4)CC2)cc1\n",
      "O=S(=O)(NCCc1ccccn1)c1ccc(F)c(F)c1\n",
      "O=C(CCCc1nc2ccccc2s1)N1CCN(S(=O)(=O)c2cccs2)CC1\n",
      "Nc1ccc(CCS(N)(=O)=O)cc1\n",
      "O=S(=O)(N[C@@H]1C[C@H]2CC[C@@H]1C2)c1ccc2c(c1)OCCO2\n",
      "O=C(CCC(=O)N1CCc2ccccc2C1)N1CCN(S(=O)(=O)c2ccccc2)CC1\n",
      "CS(=O)(=O)N1CCC(C(=O)N2CCc3ccccc3C2)CC1\n",
      "O=S(=O)(Nc1cccnc1)c1ccc2c(c1)OCCO2\n",
      "Cc1sc2ncnc(OCC(=O)c3ccc(S(=O)(=O)N4CCCC4)cc3)c2c1C\n",
      "O=S(=O)(c1cccs1)N1CN(Cc2cccs2)c2nc3ccccc3nc21\n",
      "CSC1=N/C(=C\\c2ccc(C)o2)C(=O)S1\n",
      "Cc1nc2scc(-c3cccs3)c2c(=O)o1\n",
      "O=C(CCNS(=O)(=O)c1cccs1)N1CCc2ccccc2C1\n",
      "C=CS(=O)(=O)c1ccc(Oc2ccc(S(=O)(=O)C=C)cc2)cc1\n",
      "O=S(=O)(c1cccc(S(=O)(=O)N2CCCC2)c1)c1cccc(S(=O)(=O)N2CCCC2)c1\n",
      "Fc1ccccc1Cn1nnc2c(-n3ccnc3)ncnc21\n",
      "CCc1ccc(NS(=O)(=O)c2cccs2)cc1\n",
      "O=C(/C=C/c1ccc(O)cc1)c1c(O)cc(O)cc1O\n",
      "NC(=O)C[N@H+]1CCCN(S(=O)(=O)c2ccc(Br)cc2)CC1\n",
      "N#CCCN1CCN(S(=O)(=O)c2ccc(S(=O)(=O)N3CCCCCC3)cc2)CC1\n",
      "Cc1cc(C)n(S(=O)(=O)c2ccc3ccccc3c2)n1\n",
      "c1cc(-c2sc(-c3ccncc3)c(-c3ccncc3)c2-c2ccncc2)ccn1\n",
      "O=C(Cc1cccs1)Nc1nncs1\n",
      "c1csc(-c2nn[n-]n2)c1\n"
     ]
    }
   ],
   "source": [
    "# df_untested=pd.read_csv('untested_molecules.csv')\n",
    "# for i in range(len(df_untested['SMILES'])):\n",
    "#     molecule=df_untested.loc[i,'SMILES']\n",
    "#     if molecule in intersect:\n",
    "#         df_untested.loc[i,selected_kinase]=1\n",
    "#         print(molecule)\n",
    "#     else:\n",
    "#         df_untested.loc[i,selected_kinase]=0\n",
    "\n",
    "# df_untested.set_index('SMILES', inplace=True)\n",
    "# df_untested.to_csv('predicted_molecules.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_untested=pd.read_csv('untested_molecules.csv')\n",
    "for i in range(len(df_untested['SMILES'])):\n",
    "    molecule=df_untested.loc[i,'SMILES']\n",
    "    if molecule in intersect_erk:\n",
    "        df_untested.loc[i,kinase_ERK2]=1\n",
    "        print(molecule)\n",
    "    else:\n",
    "        df_untested.loc[i,kinase_ERK2]=0\n",
    "\n",
    "df_untested.set_index('SMILES', inplace=True)\n",
    "df_untested.to_csv('predicted_molecules.csv')\n",
    "\n",
    "\n",
    "\n",
    "df_untested=pd.read_csv('untested_molecules.csv')\n",
    "for i in range(len(df_untested['SMILES'])):\n",
    "    molecule=df_untested.loc[i,'SMILES']\n",
    "    if molecule in intersect_pmk:\n",
    "        df_untested.loc[i,kinase_PKM2]=1\n",
    "        print(molecule)\n",
    "    else:\n",
    "        df_untested.loc[i,kinase_PKM2]=0\n",
    "\n",
    "df_untested.set_index('SMILES', inplace=True)\n",
    "df_untested.to_csv('predicted_molecules.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
