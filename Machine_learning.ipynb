{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\programdata\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\20223554\\appdata\\roaming\\python\\python38\\site-packages (from imblearn) (0.12.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\20223554\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\20223554\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# dit moet je wel weghalen bij inleveren, die staat nu ook in de yml file...\n",
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from pandas.plotting import scatter_matrix \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tested data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the .csv file\n",
    "data = pd.read_csv('cleaned_descriptor_data',index_col=0)\n",
    "\n",
    "# Scale the data with a standard scaling\n",
    "scaling=MinMaxScaler()\n",
    "scaling.fit(data)\n",
    "scaled_data=scaling.transform(data)\n",
    "df_data = pd.DataFrame(scaled_data, columns=data.columns,index=data.index)\n",
    "\n",
    "# Choose the kinase of which you want to predict the inhibition\n",
    "#selected_kinase = 'ERK2_inhibition'\n",
    "selected_kinase = 'PKM2_inhibition'    \n",
    "\n",
    "# Define train and test data\n",
    "X = df_data.drop(columns=['ERK2_inhibition','PKM2_inhibition']).copy()\n",
    "y = data[selected_kinase].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fingerprints=pd.read_csv('fingerprint_data',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load untested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_molecules=pd.read_csv('cleaned_descriptor_data_untested',index_col=0)\n",
    "untested_molecules.head()\n",
    "X_untested=untested_molecules.drop(columns=['ERK2_inhibition','PKM2_inhibition']).copy()\n",
    "y_untested=untested_molecules[selected_kinase].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_untested_fingerprints=pd.read_csv('fingerprint_data_untested',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed',\n",
      "       'MinPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2',\n",
      "       'FpDensityMorgan3', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO',\n",
      "       'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW',\n",
      "       'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0n', 'Chi1v', 'Chi3n', 'Chi3v',\n",
      "       'Ipc', 'Kappa2', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA5', 'PEOE_VSA7',\n",
      "       'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA3', 'SMR_VSA5',\n",
      "       'SMR_VSA7', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA6', 'EState_VSA3',\n",
      "       'EState_VSA4', 'EState_VSA6', 'VSA_EState1', 'VSA_EState2',\n",
      "       'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState9',\n",
      "       'NumAromaticHeterocycles', 'MolLogP', 'fr_Ar_N', 'fr_sulfonamd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(RandomForestClassifier(), n_features_to_select=50)\n",
    "rfe.fit(X, y)\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned=X[selected_features]\n",
    "X_untested_cleaned=X_untested[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with descriptors evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__n_estimators': 100}\n",
      "Cross-validation score: 0.09\n",
      "Test score: 0.0\n",
      "Confusion Matrix:\n",
      "[[216   2]\n",
      " [  6   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       222\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.96       224\n",
      "   macro avg       0.50      0.49      0.49       224\n",
      "weighted avg       0.98      0.96      0.97       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y, test_size=0.2, stratify=y,random_state=11)\n",
    "\n",
    "\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=11)],['classifier', RandomForestClassifier()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "    \n",
    "param_grid = {'classifier__n_estimators':[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='recall', cv=stratified_kfold, n_jobs=None)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "\n",
    "\n",
    "# Get the best estimator from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of 0 and 1 inhibitors in the balanced training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.973214\n",
      "1    0.026786\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [1. 1.]\n",
      "Confusion Matrix:\n",
      "[[216   2]\n",
      " [  5   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       221\n",
      "           1       0.17      0.33      0.22         3\n",
      "\n",
      "    accuracy                           0.97       224\n",
      "   macro avg       0.58      0.66      0.60       224\n",
      "weighted avg       0.98      0.97      0.97       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=40)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced = y_train_balanced.value_counts(normalize=True)\n",
    "ratio_test = y_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the balanced training set:\")\n",
    "print(ratio_train_balanced)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test)\n",
    "\n",
    "# Train the Random Forest model with the balanced training set\n",
    "rf_descriptors = RandomForestClassifier(n_estimators=600, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores = cross_val_score(rf_descriptors, X_train_balanced, y_train_balanced, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "\n",
    "rf_descriptors.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = rf_descriptors.predict(X_test)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "print(classification_report(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with fingerprints evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of 0 and 1 inhibitors in the training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.973214\n",
      "1    0.026786\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [0.97701149 1.        ]\n",
      "[[218   0]\n",
      " [  6   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       224\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97       224\n",
      "   macro avg       0.50      0.49      0.49       224\n",
      "weighted avg       1.00      0.97      0.99       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20223692\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20223692\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20223692\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fingerprints, y, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=40)\n",
    "X_train_balanced_finger, y_train_balanced_finger = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced_finger = y_train_balanced_finger.value_counts(normalize=True)\n",
    "ratio_test_finger = y_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the training set:\")\n",
    "print(ratio_train_balanced_finger)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test_finger)\n",
    "\n",
    "rf_fingerprints= RandomForestClassifier(n_estimators=600, random_state=40)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores = cross_val_score(rf_fingerprints, X_train_balanced_finger, y_train_balanced_finger, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "\n",
    "rf_fingerprints.fit(X_train, y_train)\n",
    "y_pred = rf_fingerprints.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with descriptors on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_descriptors = RandomForestClassifier(n_estimators=600)\n",
    "rf_descriptors.fit(X_cleaned, y)\n",
    "y_pred_descriptor = rf_descriptors.predict(X_untested_cleaned)\n",
    "df_y_pred_descriptor=pd.DataFrame(y_pred_descriptor,index=X.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with fingerprints on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fingerprints = RandomForestClassifier(n_estimators=600)\n",
    "rf_fingerprints.fit(X_fingerprints, y)\n",
    "y_pred_fingerprint = rf_fingerprints.predict(X_untested_cleaned)\n",
    "df_y_pred_fingerprint=pd.DataFrame(y_pred_fingerprint,index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C=CCNC(=O)CCCC(=O)NCC=C', 'C=CCOn1c(=O)c(C)[n+]([O-])c2ccccc21',\n",
       "       'C=CCn1cc(Cl)c(=O)n(CC=C)c1=O', 'CC(C)(N[O-])/C(=N/O)c1cccs1',\n",
       "       'CC(C)C(=O)Nc1cc(=O)nc2nc[nH]n12', 'CC(C)[NH+](Cc1nc2ccccc2[nH]1)C(C)C',\n",
       "       'CCC(CC)C(=O)NCc1ccccc1OC', 'CCN(CC)S(=O)(=O)c1cccc2nonc12',\n",
       "       'CCOC(=O)N=[S@@](N)(=O)c1ccc(Cl)cc1', 'CCc1nnc(NC(=O)C2CCC2)s1',\n",
       "       ...\n",
       "       'COc1ccc(OC)c(Nc2cc(-c3ccccc3)nc(N)n2)c1',\n",
       "       'Cc1nnc(SCCC(=O)Nc2nc(-c3ccccc3)ns2)s1',\n",
       "       'Cc1noc(C)c1CSc1nc2[nH]ncc2c(=O)n1-c1ccccc1',\n",
       "       'O=C(COc1ccc(Cl)cc1)Nc1nc(-c2cccs2)cs1',\n",
       "       'O=C1OCC2=C1[C@@H](c1ccc3c(c1)OCO3)Sc1ccccc1N2',\n",
       "       'O=C1c2ccccc2[C@H](Nc2ccc3c(c2)OCCO3)N1Cc1ccco1',\n",
       "       'O=S(=O)(Nc1cccc(-c2cn3ccsc3[nH+]2)c1)c1ccc(F)cc1',\n",
       "       'Oc1c(C[NH+]2CCN(c3ccccn3)CC2)cc(Cl)c2cccnc12',\n",
       "       'c1ccc(-c2csc(N3CCN(c4ccccn4)CC3)n2)cc1',\n",
       "       'c1ccc(C2=Nn3c(nnc3-c3cc(-c4ccccc4)n[nH]3)SC2)cc1'],\n",
       "      dtype='object', name='SMILES', length=528)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect=X[(df_y_pred_descriptor[0]==1)&(df_y_pred_fingerprint[0]==1)].index\n",
    "intersect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
