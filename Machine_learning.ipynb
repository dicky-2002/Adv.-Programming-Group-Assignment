{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dit moet je wel weghalen bij inleveren, die staat nu ook in de yml file...\n",
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from pandas.plotting import scatter_matrix \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tested data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the .csv file\n",
    "data = pd.read_csv('cleaned_descriptor_data',index_col=0)\n",
    "\n",
    "# Scale the data with a standard scaling\n",
    "scaling=MinMaxScaler()\n",
    "scaling.fit(data)\n",
    "scaled_data=scaling.transform(data)\n",
    "df_data = pd.DataFrame(scaled_data, columns=data.columns,index=data.index)\n",
    "\n",
    "# Choose the kinase of which you want to predict the inhibition\n",
    "#selected_kinase = 'ERK2_inhibition'\n",
    "selected_kinase = 'PKM2_inhibition'    \n",
    "\n",
    "# Define train and test data\n",
    "X = df_data.drop(columns=['ERK2_inhibition','PKM2_inhibition']).copy()\n",
    "y = data[selected_kinase].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fingerprints=pd.read_csv('fingerprint_data',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load untested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_molecules=pd.read_csv('cleaned_descriptor_data_untested',index_col=0)\n",
    "untested_molecules.head()\n",
    "X_untested=untested_molecules.drop(columns=['ERK2_inhibition','PKM2_inhibition']).copy()\n",
    "y_untested=untested_molecules[selected_kinase].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_untested_fingerprints=pd.read_csv('fingerprint_data_untested',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed',\n",
      "       'SPS', 'MinPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2',\n",
      "       'FpDensityMorgan3', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO',\n",
      "       'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW',\n",
      "       'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0n', 'Chi1v', 'Chi3v',\n",
      "       'HallKierAlpha', 'Kappa1', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11',\n",
      "       'PEOE_VSA5', 'PEOE_VSA9', 'SMR_VSA10', 'SMR_VSA3', 'SMR_VSA5',\n",
      "       'SMR_VSA7', 'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA5', 'EState_VSA3',\n",
      "       'EState_VSA5', 'EState_VSA6', 'VSA_EState1', 'VSA_EState2',\n",
      "       'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6',\n",
      "       'VSA_EState9', 'NumAromaticHeterocycles', 'MolLogP', 'fr_Ar_N',\n",
      "       'fr_sulfonamd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(RandomForestClassifier(), n_features_to_select=50)\n",
    "rfe.fit(X, y)\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned=X[selected_features]\n",
    "X_untested_cleaned=X_untested[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with descriptors evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__n_estimators': 100}\n",
      "Cross-validation score: 0.13999999999999999\n",
      "Test score: 0.0\n",
      "Confusion Matrix:\n",
      "[[216   2]\n",
      " [  6   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       222\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.96       224\n",
      "   macro avg       0.50      0.49      0.49       224\n",
      "weighted avg       0.98      0.96      0.97       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y, test_size=0.2, stratify=y,random_state=11)\n",
    "\n",
    "\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=11)],['classifier', RandomForestClassifier()]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "    \n",
    "param_grid = {'classifier__n_estimators':[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='recall', cv=stratified_kfold, n_jobs=None)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "\n",
    "\n",
    "# Get the best estimator from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of 0 and 1 inhibitors in the balanced training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.982143\n",
      "1    0.017857\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [0.99078341 1.        ]\n",
      "Confusion Matrix:\n",
      "[[217   3]\n",
      " [  3   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       220\n",
      "           1       0.25      0.25      0.25         4\n",
      "\n",
      "    accuracy                           0.97       224\n",
      "   macro avg       0.62      0.62      0.62       224\n",
      "weighted avg       0.97      0.97      0.97       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=40)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced = y_train_balanced.value_counts(normalize=True)\n",
    "ratio_test = y_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the balanced training set:\")\n",
    "print(ratio_train_balanced)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test)\n",
    "\n",
    "# Train the Random Forest model with the balanced training set\n",
    "rf_descriptors = RandomForestClassifier(n_estimators=600, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores = cross_val_score(rf_descriptors, X_train_balanced, y_train_balanced, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "\n",
    "rf_descriptors.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = rf_descriptors.predict(X_test)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "print(classification_report(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with fingerprints evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of 0 and 1 inhibitors in the training set:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "\n",
      "Ratio of 0 and 1 inhibitors in the testing set:\n",
      "0    0.982143\n",
      "1    0.017857\n",
      "Name: PKM2_inhibition, dtype: float64\n",
      "Cross-Validation Scores: [0.97926267 1.        ]\n",
      "[[220   0]\n",
      " [  4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       224\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98       224\n",
      "   macro avg       0.50      0.49      0.50       224\n",
      "weighted avg       1.00      0.98      0.99       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fingerprints, y, test_size=0.2)\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=40)\n",
    "X_train_balanced_finger, y_train_balanced_finger = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Calculate the ratio between 0 and 1 in the balanced training set and the test set\n",
    "ratio_train_balanced_finger = y_train_balanced_finger.value_counts(normalize=True)\n",
    "ratio_test_finger = y_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"Ratio of 0 and 1 inhibitors in the training set:\")\n",
    "print(ratio_train_balanced_finger)\n",
    "print(\"\\nRatio of 0 and 1 inhibitors in the testing set:\")\n",
    "print(ratio_test_finger)\n",
    "\n",
    "rf_fingerprints= RandomForestClassifier(n_estimators=600, random_state=40)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "cv_scores = cross_val_score(rf_fingerprints, X_train_balanced_finger, y_train_balanced_finger, cv=cv, scoring='recall')\n",
    "\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "\n",
    "rf_fingerprints.fit(X_train, y_train)\n",
    "y_pred = rf_fingerprints.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with descriptors on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_descriptors = RandomForestClassifier(n_estimators=600)\n",
    "rf_descriptors.fit(X_cleaned, y)\n",
    "y_pred_descriptor = rf_descriptors.predict(X_untested_cleaned)\n",
    "df_y_pred_descriptor=pd.DataFrame(y_pred_descriptor,index=X.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with fingerprints on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fingerprints = RandomForestClassifier(n_estimators=600)\n",
    "rf_fingerprints.fit(X_fingerprints, y)\n",
    "y_pred_fingerprint = rf_fingerprints.predict(X_untested_fingerprints)\n",
    "df_y_pred_fingerprint=pd.DataFrame(y_pred_fingerprint,index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COc1ccccc1-n1cnnc1SCC(=O)N1CCN(S(=O)(=O)c2ccccc2)CC1',\n",
       "       'O=C(CSc1n[nH]c(-c2cccs2)n1)N1CCN(S(=O)(=O)c2ccccc2)CC1',\n",
       "       'C=CCn1c(SCc2csc(C)n2)nc2scc(-c3ccc(C)o3)c2c1=O',\n",
       "       'COc1cccc(-c2nn(C)c3sc(C(=O)NCc4ccc(C)o4)cc23)c1',\n",
       "       'C=CCn1c(SCC(=O)N2CCOCC2)nc2scc(-c3ccco3)c2c1=O',\n",
       "       'COCCSc1ccccc1C(=O)Nc1cc(C)on1', 'Cc1nc2ccc(S(=O)(=O)Nc3ccccc3C)cc2s1',\n",
       "       'N#CCc1ccc(NS(=O)(=O)c2cccs2)cc1',\n",
       "       'Cc1cc(C)n2cc(CSc3nnnn3-c3ccc(Cl)cc3)[nH+]c2n1',\n",
       "       'Cc1cc(NC(=O)CSc2nnc(-c3ccoc3C)o2)no1',\n",
       "       'c1ccc2c(c1)ncn2Cc1nnc2sc(-c3ccncc3)nn12'],\n",
       "      dtype='object', name='SMILES')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect=X[(df_y_pred_descriptor[0]==1)&(df_y_pred_fingerprint[0]==1)].index\n",
    "intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing outcomes to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_untested=pd.read_csv('untested_molecules.csv')\n",
    "for i in range(len(df_untested['SMILES'])):\n",
    "    molecule=df_untested.loc[i,'SMILES']\n",
    "    if molecule in intersect:\n",
    "        df_untested.loc[i,selected_kinase]=1\n",
    "        print(molecule)\n",
    "    else:\n",
    "        df_untested.loc[i,selected_kinase]=0\n",
    "\n",
    "df_untested.set_index('SMILES', inplace=True)\n",
    "df_untested.to_csv('predicted_molecules.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
